##MCMC methods for parameter estimation (Algorithm 8)##
#######################################################

test_phi.8 = numeric(numIter)

#initialize number of clusters
K = floor(alpha*log(num_cust))

#initialize cluster assignment
phi.8 = numeric(xtraSpace)
phi.8[1:K] = rnorm(K, mu_base, sd_base) #for algo 8

#initialize cluster assignment
sampling = c(1:K, sample(1:K, num_cust-K, replace=TRUE))
cluster  = sample(sampling, num_cust, replace=FALSE)

#calculate number of people in each table
counts = numeric(xtraSpace)
counts[1:K] = sapply(1:K, function(r) sum(cluster == r))

#conditional prob for each cluster
prob_clust = numeric(xtraSpace) 

#sum of observations in each cluster
sum_cluster = numeric(xtraSpace)

for (ii in 1:numIter){
  
  rand_samples = sample(1:num_cust, 
                        num_cust,
                        replace=FALSE)
  
  #iteration for each observation
  for (b in 1:num_cust){
    
    j = rand_samples[b]
    
    h = K + m
    
    #removing the observation from the cluster
    counts[cluster[j]] = counts[cluster[j]]-1
    
    #reevaluating cluster assignments
    if (counts[cluster[j]]!=0){
      
      #drawing values for the aux params from G_0
      phi.8[(K+1):h] = rnorm(m, mu_base, sd_base) 
      
    } else if (counts[cluster[j]]==0 & cluster[j]!=K){
      
      #renumbering the clusters
      counts[cluster[j]]  = counts[K]
      cluster[cluster==K] = cluster[j]
      counts[K] = 0
      
      #renumbering the phi.8
      temp = phi.8[cluster[j]]
      phi.8[cluster[j]] = phi.8[K]
      phi.8[K] = temp
      
      #reducing the number of clusters and aux clusters
      K = K-1
      h = h-1
      
      #drawing values for the aux params from G_0
      phi.8[(K+2):h] = rnorm(m-1, mu_base, sd_base)
      
    } else if (counts[cluster[j]]==0 & cluster[j]==K){
      
      #reducing the number of clusters and aux clusters
      K = K-1
      h = h-1
      
      #drawing values for the aux params from G_0
      phi.8[(K+2):h] = rnorm((m-1), mu_base, sd_base)
      
    }
    
    #prob of choosing existing cluster 
    prob_clust[1:K] = log(counts[1:K]) +
      dnorm(mixDat[j], phi.8[1:K], sd_obs, log=TRUE)
    
    #prob of choosing new cluster
    prob_clust[(K+1):h] = log(alpha/m) + 
      dnorm(mixDat[j], phi.8[(K+1):h], sd_obs, log=TRUE)
    
    #normalizing constant
    prob_norm = prob_clust[1:h] - 
      logSumExp(prob_clust[1:h])
    
    #sampling new cluster assignments
    new_table = sample(1:h, 
                       1, 
                       replace = FALSE,
                       exp(prob_norm)
    )
    
    #new table addition
    if (new_table > K){
      
      cluster[j] = K+1
      phi.8[K+1] = phi.8[new_table]
      counts[K+1] = 1
      K = K+1
      
    } else {
      
      cluster[j] = new_table
      counts[new_table] = counts[new_table]+1
      
    }
    
    phi.8[(K+1):xtraSpace]  = rep(0,xtraSpace-K)
    counts[(K+1):xtraSpace] = rep(0,xtraSpace-K)
    
  } 
  
  #sampling the new parameters
  #this one here could be done using the MH algorithm
  sum_cluster = sapply(1:K, function(r) 
    sum(mixDat[cluster==r]))
  
  var_phi.8 =((var_base*var_obs)/
                (counts[1:K]*var_base+var_obs))
  
  mean_phi.8 = (var_phi.8)*
    (mu_base/var_base +
       sum_cluster/var_obs)
  
  phi.8[1:K] = rnorm(K, mean_phi.8, sqrt(var_phi.8))
  
  #storing params value for observation 
  test_phi.8[ii] = phi.8[cluster[test_obs]]
  
  if(ii > burnIn){
    
    #prob of sitting at a new table
    phi.8[(K+1):(K+m)] <- rnorm(m, mu_base, sd_base)
    
    #Calculating the predictive prob
    probPoints <- unlist(lapply(1:length(points), function(k){
      (sum(exp(
        log(counts[1:K]) + 
          dnorm(points[k],phi.8[1:K],sd_obs,log=TRUE))) + 
         sum(exp(
        log(alpha/m) + 
          dnorm(points[k],phi.8[(K+1):(K+m)],sd_obs,log=TRUE) +
          dnorm(phi.8[(K+1):(K+m)], sd_base, log=TRUE)))
      )/(length(mixDat)+alpha)
    }))
    
    val_alg8[(ii-burnIn),] <- probPoints
  }

  if (ii%%telliter == 0)
    print(sprintf("Iteration: %d", ii))
  
}

quants = apply(val_alg8, 2, quantile, probs=c(0.95, 0.05))
meanCol = colMeans(val_alg8)

datPoints8 <- data.frame(points = points, 
                         lower=quants[1,],
                         upper=quants[2,], 
                         mean=meanCol)
